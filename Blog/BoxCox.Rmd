---
title: "BoxCox"
author: "simplymathematics"
date: "March 12, 2019"
output: html_document
---

# Box-Cox Transformations
In this section, we create a histogram of all the vectors after taking a look at the data. Notice how neither of them appear particularly 'normal' and are subject to a lot of variance.
```{r}
?cars
head(cars)
par(
hist(cars$speed, nclass = 25),
hist(cars$dist, nclass = 25)
)
```
Here we build our first, naive model. It has an $R^2$ of .65.
```{r}

model1 <- lm(cars$speed ~ cars$dist)
summary(model1)

```
We can see in the scatter plot that this line doesn't seem to fit the data as well as we'd like.
```{r}
plot(cars$speed, cars$dist)
abline(model1)
model1
```
Perhaps this is due to the lack of normality in our data. Let's take a closer look.

```{r}
qqnorm(cars$speed)
qqline(cars$speed)
qqnorm(cars$dist)
qqline(cars$dist)
```
In either case, there is certainly room for improvement. However, the distance vector has larger residuals in the extrema. We can fix this with a Box-Cox transformation. First we install and use the forecast library.

```{r}
library(forecast)
```

Then we apply the transform. This is equivalent to 
$$
x \rightarrow x^\lambda
$$
where lambda is given by the ```BoxCox.lambda(x)``` function and is chosen in such a way as to minimize mean square error. The reason this works is quite complex, but is due to the nature of logarithms and their tendency to show up in the real world.

```{r}
cars2 <- cars
transform <- function(x){
  x <- BoxCox(x, lambda = BoxCox.lambda(x))
}
cars2 <- as.data.frame(sapply(cars2, transform))
sapply(cars2, hist)
sapply(cars2, qqnorm)
```
Now, let's build a new model and compare the results.

```{r}
plot(cars2$speed, cars2$dist)
model2 <- lm(cars2$dist ~ cars2$speed)
abline(model2)
model2
summary(model2)

```
Eyyo! Now our model has an $R^2$ of .72. Id' say that's a good result. However, you might be asking:

> What? Why did we magically change our data to make our model better?


Well, [this stackoverflow post](https://stackoverflow.com/questions/30053266/apply-multiple-functions-in-sapply) may clear it up a bit for you. In short, the real-world is messy and solutions to the differential equations that govern things like physics tend to be logarithmic. Let's check our transform for the data vectors vectors.

```{r}
BoxCox.lambda(cars$speed)
BoxCox.lambda(cars$dist)
```
As we can see, neither data vector was entirely normal and a better model was built using an exponential transform. Because the real-world tends to be logarithmic, applying an exponential functions reverts this. This corresponds to the physics, which suggests that stopping distance, $d$ is
$$
d = \frac{v^2}{2 \mu g}
$$
where $\mu$ is a coefficient of friction and $g$ is the acceleration due to gravity. You can see range of values provided, we can approximate this quadratic equation by transforming the data into something that's more exponential.

Note that Box-Cox transformations can be a quick way to improve your model, but that they must always be rooted in the underlying data. Otherwise, they're meaningless. In fact, we can also improve our $R^2$ by moddling several polynomials. As we can see, higher degree polynomials tend to be better. However, they are very complicated, have little to do with the real world (physical laws come in squares and cubes at most), and higher degree polynomials are subject to tremendous floating point errors. They also have a tendency to overfit.

```{r}
plot(cars, xlab = "Speed (mph)", ylab = "Stopping distance (ft)",
    las = 1, xlim = c(0, 25))
results <- c()
list <- runif(1000, 1, 10)
for(degree in list) {
  fm <- lm(dist ~ poly(speed, degree), data = cars)
  r.square <- 1-sum((fm$residuals^2))/sum((length(cars$dist)*var(cars$dist)))
  results <- rbind(results, r.square)
}
plot(list, results)
```
So, if we take a cue from the physical model, and use the ```nls()``` function of the form given above, we find that 

```{r}
#u = .4
#g = 9.8
#v = cars2$speed
#d = cars2$dist

model3 <- nls(speed ~ 1/a*dist^.5, data=cars, start = list(a=8), model = TRUE)

model4 <-nls(dist ~ a *speed^2, data = cars, start = list(a = 1))
qqnorm(model3,abline = c(0,1))
qqnorm(model4,abline = c(0,1))

```


```{r}
summary(model3)

```
$$
v = 2 x^ .5
$$

```{r}
summary(model4)
```
$$
x = \frac{v^2}{8}
$$