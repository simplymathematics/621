---
title: "HW 4"
author: "Team 2"
date: "May 1, 2019"
output:
  pdf_document:
    toc: yes
  html_document:
    pdf_document: default
    theme: cosmo
    toc: yes
    toc_float: yes
---

# OVERVIEW

In this homework assignment, we will explore, analyze and model a data set containing approximately 8000 records representing a customer at an auto insurance company. Each record has two response variables. The first response variable, `TARGET_FLAG`, is a 1 or a 0. A "1" means that the person was in a car crash. A zero means that the person was not in a car crash. The second response variable is `TARGET_AMT`. This value is zero if the person did not crash their car. But if they did crash their car, this number will be a value greater than zero

## Dependencies

Replication of our work requires the following packages in Rstudio:

```{r, echo=F, message=F, warning=F, error=F, comment=F}

# Requirements for formatting and augmenting default settings for chunks. 
library(knitr)
library(kableExtra)
library(default)
library(BBmisc)
library(forecast)

knitr::opts_chunk$set(echo=F, message=F, warning=F, error=F, comment=F) 

default(kable_styling)  <- list(bootstrap_options = c("basic"), 
                                position = "center", 
                                full_width = F,
                                font_size = NULL)

default(row_spec)  <- list(row = 0:0, bold = T)
```

```{r, echo=T}
# analyze data
library(corrplot)
library(randomForest)
library(olsrr)
library(psych)
library(caret)

#organize data
library(dplyr)
library(tidyr)

#visualize data
library(reshape2)
library(ggplot2)
library(ggpubr)

# dummy variables
library(sjmisc)
```

## Objective 

Our objective is to build multiple linear regression and binary logistic regression models on the `training` data to predict the probability that a person will crash their car and also the amount of money it will cost if the person does crash their car.

# DATA PREPARATION

The following chart outlines the variable imported from the `training.csv` dataset. 

```{r}

training <- as.data.frame(read.csv("insurance_training_data.csv"))
testing <- as.data.frame(read.csv("insurance-evaluation-data.csv"))
training<-training[,-1]

include_graphics("./hw4_vars.jpg")
```

## DATA CLEANING

During our initial review, we recognized that the dataset required cleaning before further analysis and exploration. 

```{r}
summary(str(training))
```

### Regular Expression 

We first convered the `INCOME`, `HOMEVAL`, `BLUEBOOK`, and `OLDCLAIM` varaibles from factors to numeric by removing currency characters from the dataset. 

```{r, echo=T}
# Remove currency characters from dataset 
training$HOME_VAL<-as.numeric(gsub(",","",(gsub("\\$","",as.character(training$HOME_VAL)))))
training$INCOME<-as.numeric(gsub(",","",(gsub("\\$","",as.character(training$INCOME)))))
training$BLUEBOOK<-as.numeric(gsub(",","",(gsub("\\$","",as.character(training$BLUEBOOK)))))
training$OLDCLAIM<-as.numeric(gsub(",","",(gsub("\\$","",as.character(training$OLDCLAIM)))))

# Remove "z_" characters from dataset
training$MSTATUS<-gsub("z_","",as.character(training$MSTATUS))
training$URBANICITY<-gsub("z_","",as.character(training$URBANICITY))
training$CAR_TYPE<-gsub("z_","",as.character(training$CAR_TYPE))
training$EDUCATION<-gsub("z_","",as.character(training$EDUCATION))
training$JOB<-gsub("z_","",as.character(training$JOB))
```

### Imputation 

For the following incomplete cases, we replaced the value of `NULL` data with the mean of the relevant data vector.

```{r}
trainNA <- training %>%
  summarise_all(funs(sum(is.na(.)))) %>% gather() 

trainNA[rowSums(trainNA > 0)>1,] %>% kable() %>% kable_styling()
```


```{r, echo=T}
for(i in c(4,6,7,9,24)){
  training[is.na(training[,i]), i] <- mean(training[,i], na.rm = TRUE)
}
```

We found that mean imputation of the `HOME_VAL` and `INCOME` values do not change the variance. However, this assumes that these people have both income and homes. If not, this would bias our models.  

We also found one record in which car age was less than zero. We also choose to impute this value with its corresponding mean. 

```{r, echo=T}
training$CAR_AGE[training$CAR_AGE<0] <- mean(training$CAR_AGE)
```

### Binary Variables 

We then converted `PARENT1`, `MSTATUS`, `SEX`, `CAR_USE`, `RED_CAR`, `REVOKED`, and `URBANICITY` into binary variables. 

```{r, echo=T}
training <- training %>% 
  mutate(PARENT1 = ifelse(PARENT1 == "No", 0, 1)) %>%
  mutate(PARENT1=as.factor(PARENT1)) %>% 
  mutate(MSTATUS = ifelse(MSTATUS == "No", 0, 1)) %>%
  mutate(MSTATUS=as.factor(MSTATUS)) %>% 
  mutate(SEX = ifelse(SEX == "M", 0, 1)) %>%
  mutate(SEX=as.factor(SEX)) %>% 
  mutate(CAR_USE = ifelse(CAR_USE == "Commercial", 0, 1)) %>%
  mutate(CAR_USE=as.factor(CAR_USE)) %>% 
  mutate(RED_CAR = ifelse(RED_CAR == "no", 0, 1)) %>%
  mutate(RED_CAR=as.factor(RED_CAR)) %>% 
  mutate(REVOKED = ifelse(REVOKED == "No", 0, 1)) %>%
  mutate(REVOKED=as.factor(REVOKED)) %>% 
  mutate(URBANICITY = ifelse(URBANICITY == "Highly Rural/ Rural", 0, 1)) %>%
  mutate(URBANICITY=as.factor(URBANICITY))

testing <- testing %>% 
  mutate(PARENT1 = ifelse(PARENT1 == "No", 0, 1)) %>%
  mutate(PARENT1=as.factor(PARENT1)) %>% 
  mutate(MSTATUS = ifelse(MSTATUS == "No", 0, 1)) %>%
  mutate(MSTATUS=as.factor(MSTATUS)) %>% 
  mutate(SEX = ifelse(SEX == "M", 0, 1)) %>%
  mutate(SEX=as.factor(SEX)) %>% 
  mutate(CAR_USE = ifelse(CAR_USE == "Commercial", 0, 1)) %>%
  mutate(CAR_USE=as.factor(CAR_USE)) %>% 
  mutate(RED_CAR = ifelse(RED_CAR == "no", 0, 1)) %>%
  mutate(RED_CAR=as.factor(RED_CAR)) %>% 
  mutate(REVOKED = ifelse(REVOKED == "No", 0, 1)) %>%
  mutate(REVOKED=as.factor(REVOKED)) %>% 
  mutate(URBANICITY = ifelse(URBANICITY == "Highly Rural/ Rural", 0, 1)) %>%
  mutate(URBANICITY=as.factor(URBANICITY))
```

### Dummy Variables 

Lastly, we changed the factors in the `CAR_TYPE`, `EDUCATION`, and `JOB` variables to dummy variables. Note that we discovered `JOB` had four `NULL` values. We choose to drop these values from our analysis. 

```{r, echo=T}
training <- training %>% 
  to_dummy(CAR_TYPE, EDUCATION, JOB, suffix = "label") %>% 
  bind_cols(training) %>% 
  select(TARGET_FLAG, everything()) %>%
  select(-CAR_TYPE, -EDUCATION, -JOB, -JOB_) %>% 
  mutate(URBANICITY=as.factor(URBANICITY))

training[,1:20] <- sapply(training[,1:20],as.factor)

testing <- testing %>% 
  to_dummy(CAR_TYPE, EDUCATION, JOB, suffix = "label") %>% 
  bind_cols(testing) %>% 
  select(TARGET_FLAG, everything()) %>%
  select(-CAR_TYPE, -EDUCATION, -JOB, -JOB_) %>% 
  mutate(URBANICITY=as.factor(URBANICITY))

testing[,1:20] <- sapply(testing[,1:20],as.factor)
```


# DATA EXPLORATION

## Summary Statistics 

We look at summary of the data below. Note that the stars next to the variable names indicate which variables are factors in our new dataset. 

```{r}
round(describe(training, na.rm = F, skew = F), 2) %>% kable() %>% kable_styling()
```

## Distributions

Below, we examine the distribution of variables using histograms, density plots, violin plots, and bar plots.  

#### Numeric Variables Distributions

Our numeric variables are shown below using the following histograms and density plots.

```{r, fig.height=5}
training %>%
  select_if(is.numeric) %>%               # Keep only numeric columns
  gather() %>%                            # Convert to key-value pairs
  ggplot(aes(value)) +                    # Plot the values
  geom_histogram(aes(y =..density..,      # Histogram plot
                     fill=..count..))+
  geom_density(col="black") +             # Density plot
  scale_fill_gradient()+                  # Apply gradient to count
  facet_wrap(~key, ncol = 3,              # Plot in separate panels
             scales = 'free') 
```

#### Binary Variable Distribution 

The following violin plots show the distribution of our binary variables. 

```{r fig.height=4}
p1 <- ggplot(training, aes(x=TARGET_FLAG, y=log(TARGET_AMT+1))) + geom_violin()
p2 <- ggplot(training, aes(x=MSTATUS, y=log(TARGET_AMT+1))) + geom_violin()
p3 <- ggplot(training, aes(x=SEX, y=log(TARGET_AMT+1))) + geom_violin()
p4 <- ggplot(training, aes(x=CAR_USE, y=log(TARGET_AMT+1))) + geom_violin()
p5 <- ggplot(training, aes(x=RED_CAR, y=log(TARGET_AMT+1))) +  geom_violin()
p6 <- ggplot(training, aes(x=REVOKED, y=log(TARGET_AMT+1))) + geom_violin()
p7 <- ggplot(training, aes(x=URBANICITY, y=log(TARGET_AMT+1))) + geom_violin()
p8 <- ggplot(training, aes(x=PARENT1, y=log(TARGET_AMT+1))) + geom_violin()


ggarrange(p1, p2, p3, p4, p5, p6, p7, p8, ncol = 4, nrow = 2)
```

#### Dummy Variable Distributions

```{r, fig.height=3}
car <- training %>% select(TARGET_FLAG, starts_with("CAR_TYPE")) %>% melt(id.vars = "TARGET_FLAG")

ggplot(car) +
  geom_bar(aes(value, fill=variable)) + 
  facet_wrap(~variable, scales="free_x", ncol=3)+
  ggtitle("CAR_TYPE")

educ <- training %>% select(TARGET_FLAG, starts_with("EDUCATION")) %>% melt(id.vars = "TARGET_FLAG")

ggplot(educ) +
  geom_bar(aes(value, fill=variable)) + 
  facet_wrap(~variable, scales="free_x", ncol=3)+
  ggtitle("EDUCATION")

job <- training %>% select(TARGET_FLAG, starts_with("JOB")) %>% melt(id.vars = "TARGET_FLAG")

ggplot(job) +
  geom_bar(aes(value, fill=variable)) + 
  facet_wrap(~variable, scales="free_x", ncol=4)+
  ggtitle("JOB")
```

## Scatter plot matrix

We then build scatter plot matrix for continious variables

```{r, fig.height=4}
training %>% 
  select_if(is.numeric) %>%
  pairs.panels(
    method = "pearson", # correlation method
    hist.col = "#00AFBB",
    density = T  # show density plots
             )
```

## Correlation  

We can see our correlation matrix below. A dark blue circle represents a strong positive relationship and a dark red circle represents a strong negative relationship between two variables. 

```{r, fig.height=4}
results1 <- training %>%
  select_if(is.numeric) %>% 
  cor(method = 'pearson', use = 'complete.obs')

corrplot(results1, method = 'circle')
```

Finally, we can use the `randomforest` package to verify our assumptions from the correlation plot.

```{r}
training2 <- training
training2$TARGET_AMT<- NULL
training2$TARGET_FLAG<- NULL
target1 <- training$TARGET_AMT
target2 <- as.numeric(training$TARGET_FLAG)

fit1 <- randomForest(training2, target1, importance = TRUE, ntree = 50)

varImpPlot(fit1)

fit2 <- randomForest(training2, target2, importance = TRUE, ntree = 50)

varImpPlot(fit2)
```
## Data transformations

Because many of these values are count points, data transformations are inappropriate. However, INCOME, and HOME_VALUE appear to arise from Gaussian processes and would benefit by being transformed via BoxCox.

```{r}
training$INCOME   <- as.numeric(as.character(training$INCOME))
training$HOME_VAL <- as.numeric(as.character(training$HOME_VAL))

training$INCOME <- BoxCox(training$INCOME, lambda = BoxCox.lambda(training$INCOME))
training$HOME_VAL <- BoxCox(training$HOME_VAL, lambda = BoxCox.lambda(training$HOME_VAL))

```




# BUILD MODELS

Using the transformed data above, we developed two multiple linear regression and three binary logistic regression models. Through these models, we hope to predict **(1)** the probability that a person will crash their car and **(2)** the amount of money it will cost if the person does crash their car.

## Multiple Linear Regression 

MLR for `TARGET_AMT`.

### MLR 1

The following MLR model seeks to predict `TARGET_AMT` using all variables. 

```{r, echo=F}
lm_train <- training %>% select(-TARGET_FLAG)
select_if(lm_train, is.numeric)




lm1<- lm(TARGET_AMT~., lm_train)
summary(lm1)
```

#### Model Analysis 

The low f-statistic suggests a weak relationship when using all predicted and response variables. The Adjusted R^2 value of 0.06681 means that only 6.681% of the variance observed in the `TARGET_AMT` variable can be explained when using all response variables.  

Additionally, all variables show small t-statistics, which means there is a higher degree of variability in the coefficient estimates for all variables with the exceptions of the following: 

```{r}
tstat <- as.data.frame(summary(lm1)$coefficients[,3])

names(tstat)[1] <- "tstat"

tstat %>% subset(tstat >5) %>% kable() %>% kable_styling()
```
From this model, only the following variables had significance levels less than 0.05%. 

```{r}
pval <- as.data.frame(summary(lm1)$coefficients[,4])
names(pval)[1] <- "pval"

pval %>% subset(pval < .05) %>% round(4) %>% kable() %>% kable_styling()
```

The residual plots below show that our data as is should not be used for linear modeling without futher data transformations. The normality assumption for linear regression is not met as the residuals do not follow a straight line and the data does not meet homoscedastic assumption. The line is not horizontal and the residuals are not randomly-distributed around it.  

```{r, fig.height=4}
layout(matrix(c(1,3,2,4),2,2)) 
plot(lm1)
```
### MLR 2

The following model is based off of the variables in model 1 with high t- and significant p-values. 

```{r, echo=F}
lm2<- lm(TARGET_AMT~CAR_TYPE_Minivan+KIDSDRIV+INCOME+PARENT1+MSTATUS+SEX+TRAVTIME+CAR_USE+TIF+CLM_FREQ+REVOKED+MVR_PTS+CAR_AGE+URBANICITY, lm_train)
summary(lm2)
```

#### Model Analysis

Changing the coefficients increased our f-statistic, however the R-square value is still too low to make inference from this model. Our residual plots still show our model is not appropriate for linear regression. 

```{r}
layout(matrix(c(1,3,2,4),2,2)) 
plot(lm2)
```


## Binary Logistic Regression

We tested several logistic models both before and after transforming the data in various ways. Further information can be found the the logistic_modeling.Rmd appendix. The model with the best performance used the raw data, without any transformations. Below, we import it into this file as an R object to help us draw conclusions.


```{r, echo = FALSE}
load(file = "logistic_object.Rdata")
log.summary <- summary(model_1)
log.summary
```

# SELECT MODELS

## MLR Evaluation 

Use a metric such as Adjusted R2, RMSE, etc. Explain how you can make inferences from the model, discuss multi-collinearity issues (if any), and discuss other relevant model output.  

Using the training data set, evaluate the multiple linear regression model based on:

### Coefficient Analysis

TODO: talk about coefficients in linear model



```{r}
lm.summary1 <- summary(lm1)
lm.summary2 <- summary(lm2)

```

### R Square

```{r}
lm.summary1$r.squared
lm.summary2$r.squared

```

### Adjusted R2

```{r}
lm.summary1$adj.r.squared
lm.summary2$adj.r.squared

```


### F-statistic
```{r}
lm.summary1$fstatistic
lm.summary2$fstatistic

```




### Residual plots. 

```{r}
plot(lm.summary1$residuals)
plot(lm.summary2$residuals)

```

Noticeably, the vast majority of our error lies in the region where the Z-score is greater than 2. This means that our model has strong predictive power for relatively safe drivers and very poor predictive power for the riskiest of drivers. Additionally, since our model consistently under-predicts the cost associated with the most dangerous drivers, we could easily deny them coverage and move on with our lives. The tendency for risky drivers to have accidents that far out-pace the cost of a signle vehicle has to do with their propensity to be involved in catastrophic accidents that cause more damage than the cost of a single vehicle, cementing our stance that these people should simply not be insured.

## BLR Evaluation 



Use a metric such as log likelihood, AIC, ROC curve, etc. Using the training data set, evaluate the binary logistic regression model based on:

```{r}
require(pROC)
require(pscl)
log.predict<-predict(model_1, test, type='response')
par(pty = "s")
pROC <- roc(test$TARGET_FLAG, log.predict,
smooth=FALSE, plot = TRUE, print.auc=TRUE,legacy.axes =TRUE,  col="red", main ="ROC Curve")
summary

```

### Accuracy

```{r}
probabilities <- model_1 %>% predict(test, type = "response")
predicted.classes <- ifelse(probabilities > 0.5, 1, 0)
cm<-confusionMatrix(as.factor(predicted.classes), as.factor(test$TARGET_FLAG), dnn = c("Prediction", "Reference"), positive = '1')
cm
#Accuracy
acc<-cm$overall["Accuracy"]; names(acc)<-NULL
#Error Rate
err<-1 - acc; names(err)<-NULL
#Precision
prec<-cm$byClass["Precision"]; names(prec)<-NULL
#Sensivity
sens<-cm$byClass["Sensitivity"]; names(sens)<-NULL
#Specifity
spec<-cm$byClass["Specificity"]; names(spec)<-NULL
#F1 Score
f1<-cm$byClass["F1"]; names(f1)<-NULL
list(accuracy=acc, error_rate=err, precision=prec, sensitivity=sens, specificity=spec, F1=f1)

```



## Predictions 

Logistic Model:

```{r, echo=T}
test$TARGET_AMT <- NULL
labels <- test$TARGET_FLAG
test$TARGET_FLAG <- NULL
library(caret)
test$INDEX <- NULL
pred1 <- predict(model_1, test)
```

Linear Model:

```{r, echo=T}
testing$INCOME <- as.numeric(testing$INCOME)
pred.linear <- predict(lm2, testing)
testing$TARGET_AMT <- pred.linear
write.csv(testing, "predictions.csv")
```